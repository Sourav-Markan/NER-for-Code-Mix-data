{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes named entity recognition for code mix data experimenting with different machine learning classification algorithms with word, character and lexical features. The algorithms used for NER in this notebook are Decision tree, Long Short-Term Memory (LSTM), and Conditional Random Field (CRF). I have implemented the model using scikit-learn and keras library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA-SET "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are training our NER model for code mix data mainly Hindi-English. We have taken Hindi-English code-mixed tweets containing tweets from last 8 years (on themes like legislative issues, sports, etc from the Indian subcontinent point of view). For more information of Dataset refer to http://aclweb.org/anthology/W18-2405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv,sys,re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the NER dataset into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the data is loaded into a Pandas DataFrame. This can be done easily using the read_csv function, specifying that the separator is a comma. It's also useful to keep the blank lines, which are helpful later for determining the sentence breaks.\n",
    "\n",
    "Once the data is loaded into a DataFrame, Now we have easy access to columns allows a couple of useful things to be done - group the data by the \"ne\" column to see the distributions of each tag, and extract the classes (disregarding 'O' and blank lines with NaN values) as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tag  counts\n",
      "0  B-Loc     762\n",
      "1  B-Org    1432\n",
      "2  B-Per    2138\n",
      "3  I-Loc      31\n",
      "4  I-Org      90\n",
      "5  I-Per     554\n",
      "6  Other   63499\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ner_data = pd.read_csv(\"./Twitterdata/annotatedData.csv\", sep=\",\", header=None, skip_blank_lines=False, encoding=\"utf-8\")\n",
    "ner_data = ner_data[1:]\n",
    "ner_data.columns = [\"sen_num\", \"word\", \"tag\"]\n",
    "\n",
    "# Explore thbe distribution of NE tags in the dataset\n",
    "tag_distribution = ner_data.groupby(\"tag\").size().reset_index(name='counts')\n",
    "print(tag_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Per', 'Other', 'B-Org', 'I-Org', 'B-Loc', 'I-Per', 'I-Loc']\n"
     ]
    }
   ],
   "source": [
    "# Extract the useful classes (not 'O' or NaN values) as a list\n",
    "classes = list(filter(lambda x: x not in [\"O\", np.nan], list(ner_data[\"tag\"].unique())))\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features corresponding to every word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature set consists of word, character and lexical level information like char N-Grams of Gram size 2 and 3 for suffixes, patterns for punctuation, emoticons, numbers, numbers inside strings, social media specific characters like ‘#’, ‘@’ and\n",
    "also previous tag information, and the same all features of the previous and next tokens are used as context features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def word2features(sent, i,word2idx,tag2idx,word2Suff2idx,word3Suff2idx,wordLower2idx,binaryIdx):\n",
    "        word = sent[i][0]  \n",
    "        features = {\n",
    "            'bias': 1.0,\n",
    "            'word': word2idx[word],\n",
    "            'word.lower()': wordLower2idx[word.lower()],\n",
    "            'word[-3:]': word3Suff2idx[word[-3:]],\n",
    "            'word[-2:]': word2Suff2idx[word[-2:]],\n",
    "            'word.isupper()': binaryIdx[str(word.isupper())],\n",
    "            'word.istitle()': binaryIdx[str(word.istitle())],\n",
    "            'word.isdigit()': binaryIdx[str(word.isdigit())],\n",
    "            'word.startsWith#()': binaryIdx[str(word.startswith(\"#\"))],\n",
    "            'word.startsWith@()': binaryIdx[str(word.startswith(\"@\"))],\n",
    "            'word.1stUpper()': binaryIdx[str(word[0].isupper())],\n",
    "            'word.isAlpha()': binaryIdx[str(word.isalpha())],\n",
    "            'word.Tag': tag2idx[sent[i][1]],\n",
    "        }\n",
    "        if i > 0:\n",
    "            word1 = sent[i-1][0]\n",
    "            features.update({\n",
    "                '-1:word': word2idx[word1],\n",
    "                '-1:word.lower()': wordLower2idx[word1.lower()],\n",
    "                '-1:word.istitle()': binaryIdx[str(word1.istitle())],\n",
    "                '-1:word.isupper()': binaryIdx[str(word1.isupper())],\n",
    "                '-1:word.istitle()': binaryIdx[str(word1.istitle())],\n",
    "                '-1:word.isdigit()': binaryIdx[str(word1.isdigit())],\n",
    "                '-1:word.startsWith#()': binaryIdx[str(word1.startswith(\"#\"))],\n",
    "                '-1:word.startsWith@()': binaryIdx[str(word1.startswith(\"@\"))],\n",
    "                '-1:word.1stUpper()': binaryIdx[str(word1[0].isupper())],\n",
    "                '-1:word.isAlpha()': binaryIdx[str(word1.isalpha())],\n",
    "            })\n",
    "        else:\n",
    "            features['BOS'] = binaryIdx[str(\"True\")]\n",
    "\n",
    "        if i < len(sent)-1:\n",
    "            word1 = sent[i+1][0]\n",
    "            features.update({\n",
    "                '+1:word': word2idx[word1],\n",
    "                '+1:word.lower()': wordLower2idx[word1.lower()],\n",
    "                '+1:word.istitle()': binaryIdx[str(word1.istitle())],\n",
    "                '+1:word.isupper()': binaryIdx[str(word1.isupper())],\n",
    "                '+1:word.istitle()': binaryIdx[str(word1.istitle())],\n",
    "                '+1:word.isdigit()': binaryIdx[str(word1.isdigit())],\n",
    "                '+1:word.startsWith#()': binaryIdx[str(word1.startswith(\"#\"))],\n",
    "                '+1:word.startsWith@()': binaryIdx[str(word1.startswith(\"@\"))],\n",
    "                '+1:word.1stUpper()': binaryIdx[str(word1[0].isupper())],\n",
    "                '+1:word.isAlpha()': binaryIdx[str(word1.isalpha())],\n",
    "            })\n",
    "        else:\n",
    "            features['EOS'] = binaryIdx[str(\"True\")]\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "            \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sent\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent,word2idx,tag2idx,word2Suff2idx,word3Suff2idx,wordLower2idx,binaryIdx):\n",
    "#    print (sent)\n",
    "    return list(word2features(sent, i,word2idx,tag2idx,word2Suff2idx,word3Suff2idx,wordLower2idx,binaryIdx) for i in range(len(sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features vector corresponding to each sentence uses following features:\n",
    "- Character N-Grams\n",
    "- Word N-Gram\n",
    "- Capitalization\n",
    "- Mentions and Hashtags\n",
    "- Numbers in String\n",
    "- Previous Word Tag\n",
    "- Common Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericFeatures():\n",
    "    data = pd.read_csv(\"./Twitterdata/annotatedData.csv\", encoding=\"latin1\")\n",
    "    data = data.fillna(method=\"ffill\")\n",
    "\n",
    "    words = list(set(data[\"Word\"].values))\n",
    "    words.append(\"ENDPAD\")\n",
    "    tags = list(set(data[\"Tag\"].values))\n",
    "#     print (words)\n",
    "    print (tags)\n",
    "\n",
    "\n",
    "\n",
    "    max_len = 50\n",
    "    word2idx = {w: i for i, w in enumerate(words)}\n",
    "    tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "    word2Suff2idx = {w[-2:]: i for i, w in enumerate(words)}\n",
    "    word3Suff2idx = {w[-3:]: i for i, w in enumerate(words)}\n",
    "    wordLower2idx = {w.lower(): i for i, w in enumerate(words)}\n",
    "    binaryIdx = {\"True\": 1, \"False\": 0}\n",
    "\n",
    "#     print (binaryIdx[str(\"False\")])\n",
    "\n",
    "    # X = [[binaryIdx[str(w[5]] for w in s] for s in features]\n",
    "\n",
    "\n",
    "    getter = SentenceGetter(data)\n",
    "    # sent = getter.get_next()\n",
    "    sentences = getter.sentences\n",
    "    #print (sentences)\n",
    "    \n",
    "    X = list(sent2features(s,word2idx,tag2idx,word2Suff2idx,word3Suff2idx,wordLower2idx,binaryIdx) for s in sentences)\n",
    "    #print (pd.DataFrame(X[0]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Per', 'Other', 'B-Loc', 'I-Loc', 'I-Org', 'B-Org', 'B-Per']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "featureVec = numericFeatures()\n",
    "csv_columns = ['+1:word', '+1:word.1stUpper()', '+1:word.isAlpha()', '+1:word.isdigit()', '+1:word.istitle()','+1:word.isupper()', '+1:word.lower()', '+1:word.startsWith#()', '+1:word.startsWith@()', 'BOS', '-1:word', '-1:word.1stUpper()', '-1:word.isAlpha()', '-1:word.isdigit()', '-1:word.istitle()', '-1:word.isupper()','-1:word.lower()', '-1:word.startsWith#()', '-1:word.startsWith@()', 'EOS', 'bias', 'word', 'word.1stUpper()', 'word.isAlpha()', 'word.isdigit()', 'word.istitle()','word.isupper()', 'word.lower()', 'word.startsWith#()', 'word.startsWith@()', 'word[-2:]', 'word[-3:]', 'word.Tag']\n",
    "print(len(csv_columns))\n",
    "\n",
    "with open('featureVector.csv', 'w') as ofile:\n",
    "    writer = csv.DictWriter(ofile, csv_columns)\n",
    "    writer.writeheader()\n",
    "    for sen in featureVec:\n",
    "        for word in sen:\n",
    "            # print d\n",
    "            writer.writerow(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have experimented different classifier for identifying language. Further we will determine the effect of each feature and\n",
    "parameter of different models by performing several experiments with some set of feature vectors at a time and all at a time simultaneously changing the values of the parameters of our language classifier models like maximum depth of the tree for Decision tree model, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision tree..\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-Loc       0.34      0.33      0.34       153\n",
      "       B-Org       0.97      0.97      0.97     16653\n",
      "       I-Per       0.48      0.47      0.47       202\n",
      "       Other       0.00      0.00      0.00        10\n",
      "       B-Per       0.15      0.22      0.18        23\n",
      "       I-Org       0.57      0.58      0.57       350\n",
      "       B-Loc       0.63      0.61      0.62       645\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     18036\n",
      "   macro avg       0.45      0.45      0.45     18036\n",
      "weighted avg       0.94      0.94      0.94     18036\n",
      "\n",
      "Decision Tree F1 score: 0.94\n",
      "Results for Naive Bayes...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-Loc       0.06      0.16      0.08       153\n",
      "       B-Org       0.97      0.77      0.86     16653\n",
      "       I-Per       0.06      0.27      0.09       202\n",
      "       Other       0.00      0.30      0.01        10\n",
      "       B-Per       0.01      0.22      0.01        23\n",
      "       I-Org       0.15      0.22      0.18       350\n",
      "       B-Loc       0.27      0.48      0.35       645\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     18036\n",
      "   macro avg       0.22      0.34      0.23     18036\n",
      "weighted avg       0.91      0.74      0.81     18036\n",
      "\n",
      "Naive Bayes F1 score: 0.66\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-Loc       0.06      0.16      0.08       153\n",
      "       B-Org       0.97      0.77      0.86     16653\n",
      "       I-Per       0.06      0.27      0.09       202\n",
      "       Other       0.00      0.30      0.01        10\n",
      "       B-Per       0.01      0.22      0.01        23\n",
      "       I-Org       0.15      0.22      0.18       350\n",
      "       B-Loc       0.27      0.48      0.35       645\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     18036\n",
      "   macro avg       0.22      0.34      0.23     18036\n",
      "weighted avg       0.91      0.74      0.81     18036\n",
      "\n",
      "SVM F1 score: 0.66\n",
      "Results for Random Forest...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-Loc       0.75      0.02      0.04       153\n",
      "       B-Org       0.94      1.00      0.97     16653\n",
      "       I-Per       0.89      0.08      0.15       202\n",
      "       Other       0.00      0.00      0.00        10\n",
      "       B-Per       0.00      0.00      0.00        23\n",
      "       I-Org       0.95      0.25      0.39       350\n",
      "       B-Loc       0.77      0.35      0.48       645\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     18036\n",
      "   macro avg       0.61      0.24      0.29     18036\n",
      "weighted avg       0.93      0.94      0.92     18036\n",
      "\n",
      "random Forest F1 score: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X = pd.read_csv('./featureVector.csv')\n",
    "\n",
    "y = X['word.Tag']\n",
    "\n",
    "# removing the Tag column from X to keep it as feature only.\n",
    "X.drop('word.Tag', axis=1, inplace=True)\n",
    "\n",
    "# handelling the NaN and inf values in the dataset\n",
    "X=X.astype('float32')\n",
    "y=y.astype('float32')\n",
    "X = np.nan_to_num(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=32, class_weight=dict([{0:1,1:1}, {0:1,1:50}, {0:1,1:18},{0:1,1:1940}, {0:1,1:70},{0:1,1:3},{0:1,1:25}]))\n",
    "gnb = GaussianNB()\n",
    "svm = SVC(gamma='auto')\n",
    "clf = RandomForestClassifier(max_depth=10)\n",
    "\n",
    "# fit\n",
    "dtc.fit(X_train, y_train)\n",
    "gnb.fit(X_train, y_train)\n",
    "#svm.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = dtc.predict(X_test)\n",
    "target_names = ['I-Loc', 'B-Org', 'I-Per', 'Other', 'B-Per', 'I-Org', 'B-Loc']\n",
    "\n",
    "# print\n",
    "print (\"Results for Decision tree..\")\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "# f1 score\n",
    "score = f1_score(y_pred, y_test, average='weighted')\n",
    "print( \"Decision Tree F1 score: {:.2f}\".format(score))\n",
    "\n",
    "\n",
    "print (\"Results for Naive Bayes...\")\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# f1 score\n",
    "score = f1_score(y_pred, y_test, average='weighted')\n",
    "print (\"Naive Bayes F1 score: {:.2f}\".format(score))\n",
    "\n",
    "\n",
    "# print\n",
    "print (\"SVM\")\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "# f1 score\n",
    "score = f1_score(y_pred, y_test, average='weighted')\n",
    "print( \"SVM F1 score: {:.2f}\".format(score))\n",
    "\n",
    "\n",
    "\n",
    "print( \"Results for Random Forest...\")\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# f1 score\n",
    "score = f1_score(y_pred, y_test, average='weighted')\n",
    "print (\"random Forest F1 score: {:.2f}\".format(score))\n",
    "\n",
    "# # Cross validation on Data\n",
    "# pred = cross_val_predict(estimator=dtc, X=X, y=y, cv=5)\n",
    "# print(classification_report(pred, y, target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
